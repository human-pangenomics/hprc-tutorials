{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Read Variant Calling With Giraffe & DeepVariant\n",
    "\n",
    "The tutorial demonstrates variant calling using the Human Pangenome Reference Consortium's (HPRC) year 1 Minigraph/CACTUS pangenome with the Giraffe/DeepVariant pipeline for calling germline small variants. \n",
    "\n",
    "For this demonstration, we will work with a region of chromosome 1 containing, among others, the RHCE gene which is a a challenging medically-relevant gene. \"Challenging medically-relevant genes\" are difficult to assess with short-read sequencing but are part of a recent benchmark truthset ([CRMG v1.0](https://www.nature.com/articles/s41587-021-01158-1)). The genomic interval extracted was `chr1:25053647-25685365` ([see in the UCSC Genome Browser](https://genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&position=chr1%3A25053647%2D25685365)). \n",
    "The reads and pangenome in this workspace correspond to this slice of the genome.\n",
    "\n",
    "An Illumina dataset (produced by Google and made publicly available) with 30X coverage of HG002 has been sliced on the relevant region (as explained above). \n",
    "\n",
    "This workspace uses one of the HPRC's year 1 pangenomes created with the [Minigraph/CACTUS pipeline](https://github.com/ComparativeGenomicsToolkit/cactus/blob/master/doc/pangenome.md). For the Giraffe/DeepVariant pipeline, it is now recommended to use haplotype sampling on the full GRCh38-based graph (v1.1). Information about the HPRC's pangenome releases can be found in the HPRC's [pangenome resources GitHub repo](https://github.com/human-pangenomics/hpp_pangenome_resources).\n",
    "For this demonstration, we extracted the sub-graph of the chr1 region.\n",
    "\n",
    "Load some packages that we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         ## for holding workspace table data in dataframes\n",
    "import os                   ## for reading in bucket location\n",
    "from IPython.display import Image, display ## for showing images in the notebook\n",
    "import cyvcf2                  ## to read VCF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick look at the data\n",
    "\n",
    "First let's count the nodes, edges, and the total sequence in the pangenome graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!vg stats -zl rhce_data/hprc-v1.0-mc-grch38.chr1_25053647_25685365.gbz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the `stats` subcommand from vg, asking to print the graph's size (`-z`) and total length (`-l`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we count the number of paths (haplotypes) in the pangenome, and print the length of a couple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vg paths -Lx rhce_data/hprc-v1.0-mc-grch38.chr1_25053647_25685365.gbz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `paths` subcommand is all about paths. Here we count them by listing them (`-L`) and counting the number of lines in the output with `wc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vg paths -Ex rhce_data/hprc-v1.0-mc-grch38.chr1_25053647_25685365.gbz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-E` option lists all the paths and their length. They are about 600 Kbp long.\n",
    "\n",
    "Finally, let's have a quick look at two sequencing reads in one of the FASTQ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zcat rhce_data/HG002.chr1_25053647_25685365.R1.fastq.gz | head -8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping reads to the pangenome with vg giraffe\n",
    "\n",
    "Here we show a **minimal command** to map the sequencing reads (gzipped FASTQ files), to the pangenome (GBZ file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vg giraffe -Z rhce_data/hprc-v1.0-mc-grch38.chr1_25053647_25685365.gbz -t 4 -f rhce_data/HG002.chr1_25053647_25685365.R1.fastq.gz -f rhce_data/HG002.chr1_25053647_25685365.R2.fastq.gz -o gaf > test.gaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pangenome in GBZ format is given with `-Z` while the reads are given with `-f`.\n",
    "If needed, giraffe will make the necessary *distance* and *minimizer* indexes. \n",
    "\n",
    "**Note**: if indexes are available, for example for public pangenomes, it is better to use them rather than recreate them because it can take some time and a fair amount of memory to build on large pangenomes.\n",
    "\n",
    "The output was redirected to the `test.gaf` file which represents the mapped reads in the [GAF format](https://github.com/lh3/gfatools/blob/master/doc/rGFA.md#the-graph-alignment-format-gaf). Let's have a look at the first read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head -1 test.gaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping to the pangenome and making a BAM relative to a reference\n",
    "\n",
    "If you are just interested in the read alignment relative to a reference, i.e. the reads aligned to the pangenome and then projected(/surjected) to the reference path, you might want to **output a BAM directly**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo GRCh38.chr1 > ref.paths.txt\n",
    "!vg giraffe -Z rhce_data/hprc-v1.0-mc-grch38.chr1_25053647_25685365.gbz -t 4 -f rhce_data/HG002.chr1_25053647_25685365.R1.fastq.gz -f rhce_data/HG002.chr1_25053647_25685365.R2.fastq.gz -o BAM --ref-paths ref.paths.txt > test.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `-o BAM` we asked for a BAM output, and with `--ref-paths` we specified a file that contains a list of paths to use as reference for the projection/surjection. We created this file so that it contains `GRCh38.chr1`.\n",
    "\n",
    "Check a few aligned reads in the BAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools view test.bam | head -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the vg Giraffe-DeepVariant workflow\n",
    "\n",
    "The sections above are useful to get a feel for the commands and imagine how to modify an existing pipeline to use a pangenome as reference. \n",
    "\n",
    "In practice, more steps are involved to achieve the best performance both in term of accuracy and compute. We've implemented a **workflow to uses Giraffe and DeepVariant to call small variants** in two languages:\n",
    "\n",
    "1. A **WDL** workflow that is best suited for cloud environments like the [AnVIL platform](https://anvilproject.org/).\n",
    "2. A **Snakemake** workflow that can run locally or on a HPC more easily.\n",
    "\n",
    "This workflow integrates several steps to improve scale and accuracy, including:\n",
    "- Haplotype-sampling of the pangenome based on the kmer distribution in the reads\n",
    "- Read realignment with bamleftalign and ABRA2 to improve indel accuracy\n",
    "- Sequence renameing (`GRCh38.chr1` to `chr1`) in the BAM and VCF.\n",
    "- GPU usage for DeepVariant\n",
    "\n",
    "First, let's get the Snakemake workflow from https://github.com/vgteam/vg_snakemake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b hapsampdv https://github.com/vgteam/vg_snakemake.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can run it.\n",
    "\n",
    "If you are using the docker image from Zenodo (from `curl XXX | docker load`) you can use the Singularity images that were already cached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!snakemake --singularity-prefix /singularity_cache --use-singularity --snakefile vg_snakemake/workflow/Snakefile --configfile smk.config.rhce.yaml --cores 8 all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, if you use the \"lightweight\" docker image, there is no Singularity cache to use, you will download the images on the fly (which can take a few minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!snakemake --use-singularity --snakefile vg_snakemake/workflow/Snakefile --configfile smk.config.rhce.yaml --cores 8 all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Running the pipeline produces a lot of output which might be easier to appreciate in a Terminal. Feel free to start a terminal and run the command there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: There might be an error about \"loop devices\" (`# FATAL:   container creation failed: mount /proc/self/fd/4->/var/lib/singularity/mnt/session/rootfs error: while mounting image /proc/self/fd/4: failed to find loop device: could not attach image file to loop device: no loop devices available`). If that's the case, try to re-run the command until it finishes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the *snakemake* command:\n",
    "- `--singularity-prefix /singularity_cache --use-singularity` to use containerized tools with Singularity and to look for cached tools in a specific folder (prepared for the workshop). Again this is used if using the JupyterHub with the large files included. Otherwise, if omitted, the tools will be download when needed.\n",
    "- `--snakefile vg_snakemake/workflow/Snakefile` specifies where to find the workflow definition\n",
    "- `--configfile smk.config.rhce.yaml` points to the configuration files with info about file paths and parameters. Have a look at it.\n",
    "- `--cores 8` sets the maximum number of cores used by the workflow.\n",
    "- `all` the *rule* to run. Here \"all\" means to make all the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the files in the `results` folder.\n",
    "\n",
    "More specifically, let's have a quick look at a couple of the variants called by Giraffe-DeepVariant. They are in the `HG002.hprc-v1.0-mc-grch38.chr1_25053647_25685365.surj.snv_indels.vcf.gz` file in the `results/HG002` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zcat results/HG002/HG002.hprc-v1.0-mc-grch38.chr1_25053647_25685365.surj.snv_indels.vcf.gz | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize reads mapped across a variant site\n",
    "\n",
    "We want to visualize the read alignments on the pangenome at the location of a small variant that was called by the Giraffe-DeepVariant workflow.\n",
    "\n",
    "To do that, we will need three files:\n",
    "\n",
    "1. the pangenome index with the information about the nodes/edges/sequences (GBZ file)\n",
    "1. the VCF file with the small variant calls (one of the output of the workflow).\n",
    "1. the GAM file with the reads aligned to pangenome, sorted and indexed (another output of the workflow).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAN_IDX = 'rhce_data/hprc-v1.0-mc-grch38.chr1_25053647_25685365.gbz'\n",
    "SMALL_VCF = 'results/HG002/HG002.hprc-v1.0-mc-grch38.chr1_25053647_25685365.surj.snv_indels.vcf.gz'\n",
    "SORTED_GAM = 'results/HG002/HG002.hprc-v1.0-mc-grch38.chr1_25053647_25685365.sorted.gam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be looking at variants called by the Giraffe/DeepVariant pipeline **in an exon of RHCE**.\n",
    "For example, take a look at this region in the UCSC Genome Browser: [chr1:25408683-25408869](https://genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&position=chr1%3A25408683%2D25408869).\n",
    "\n",
    "**Note**: the pangenome that we use for this demo is a slice of the genome, starting at 25053647, so we have to remove this offset to get the appropriate coordinates in this slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_wg  = [25408683, 25408869] ## coordinate relative to the whole genome\n",
    "offset    = 25053647\n",
    "coord_sub = [pos - offset for pos in coord_wg] ## coordinate relative to our slice\n",
    "\n",
    "region_subset = 'chr1:{}-{}'.format(coord_sub[0], coord_sub[1])\n",
    "print(\"In this slice of the pangenome, the region of interest is at: \" + region_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find variant in the VCF\n",
    "\n",
    "**Open the VCF with the cyvcf2 package.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vcf_reader = cyvcf2.VCF(SMALL_VCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop over the variant in the region of interest.\n",
    "If a variant is homozygous for the alternate allele, we record its position and stop.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_pos = ''\n",
    "for record in vcf_reader('chr1:{}-{}'.format(coord_sub[0], coord_sub[1])):\n",
    "    if record.genotypes[0][0] == 1 and record.genotypes[0][1] == 1:\n",
    "        print(record)\n",
    "        var_pos = record.start\n",
    "        break\n",
    "print('There is a variant at position {}'.format(var_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This is the variant that we will look for in the pangenome and in the aligned reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract & visualize graph around the variant\n",
    "\n",
    "To zoom in to the region around the variant site, we will extract the subgraph around this region.\n",
    "In practice, we use a subcommand of `vg` to locate the subset of the pangenome of interest, and extract nodes and edges close to it.\n",
    "The most common type query is to look for a sub-region of the reference path (GRCh38 here), and then add the additional nodes/edges touching it. \n",
    "\n",
    "**Extract the graph region with `vg find`**\n",
    "* `-p` extracts a subgraph touching a region defined as *PATH:START-END*.\n",
    "Here we defined it in the *region* object above.\n",
    "* `-c` defines the **c**ontext that the subgraph should include around the queried path. Here we extend by 2 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'GRCh38.chr1:{}-{}'.format(var_pos, var_pos)\n",
    "!vg find -x {PAN_IDX} -p {region} -c 2 > graph.vg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subgraph was written in a VG file. This file can be converted to different formats using `vg view`. \n",
    "For example, you could convert it to GFA and visualize it with [Bandage](https://rrwick.github.io/Bandage/).\n",
    "We can also convert it to [DOT](https://en.wikipedia.org/wiki/DOT_%28graph_description_language%29) (a graph description language) and create an image with the `dot` command.\n",
    "\n",
    "**Now view the graph region**\n",
    "- `vg view` with the `-d` will convert a graph into a **D**OT file.\n",
    "- `-p` shows the **p**ath(s), here the *GRCh38.chr6* reference path.\n",
    "- `-C` **c**olors the non-reference nodes in red.\n",
    "- `dot` converts the DOT output into a PNG image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!vg view -dpC graph.vg | dot -Tpng -o graph.png\n",
    "display(Image(filename=\"graph.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It looks like our G/A SNV is in the pangenome. Node 3778176 represent the reference *G* allele.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract reads around the variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use vg find to extract all reads touching the subgraph that we just looked at above.**\n",
    "- `-l` specifies the (sorted and indexed) reads to query.\n",
    "- `-A` specifies to query the subgraph *graph.vg* to query.\n",
    "- `-a` count the number of line in the JSON representation of the reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!vg find -A graph.vg -l {SORTED_GAM} > reads.gam\n",
    "!vg view -a reads.gam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of reads! If we add all of them in the image, it will be hard to see what is going on.\n",
    "\n",
    "**Let's downsample them to make less busy images.**\n",
    "* `-d 0.XX` downsample to XX% of the reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vg find -A graph.vg -l {SORTED_GAM} | vg filter -d 0.1 - > reads.10pct.gam\n",
    "!vg view -a reads.10pct.gam | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize graph and reads with vg\n",
    "\n",
    "We use a similar `vg view` command as above. The only difference is that we specify the reads with `-A`, and use `-m` to disregard mapping to nodes absent from the subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vg view -A reads.10pct.gam -dpmC graph.vg | dot -Tpng -o graph.reads.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Image(filename=\"graph.reads.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We see that all reads align through the non-reference node. This is consistent with the SNV being homozygous.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional. Try the sequenceTubeMap\n",
    "\n",
    "This approach can be useful to look at a small subgraph or automate image creation. \n",
    "For other use cases, we tend to use the interactive (and better-looking) [SequenceTubeMap](https://github.com/vgteam/sequenceTubeMap). \n",
    "\n",
    "To visualize and navigate across a large pangenome and full read dataset, you would need to start a sequenceTubeMap server yourself. In the context of this workshop, **we've prepared a sequenceTubeMap server with this pangenome and reads already loaded**. \n",
    "\n",
    "Access it through the landing page then use the *Region* field to navigate to the correct position in the pangenome.\n",
    "\n",
    "To manipulate the tubemap, you can:\n",
    "- Hold-click to move horizontally\n",
    "- Scroll to zoom in/out\n",
    "- Change some visualization settings in the configuration panel below the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tubemap.screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where would one read map to the linear reference genome?\n",
    "\n",
    "We've just saw that the variant site was present in the pangenome and that reads align through it. \n",
    "Because the reads are mapped there, once they were projected to GRCh38 and fed to DeepVariant, the appropriate homozygous SNV was called.\n",
    "\n",
    "Variants in this region are actually missed when mapping the reads to the linear reference genome GRCh38. \n",
    "Let's try to figure out why by matching the sequence of one of those reads with GRCh38.\n",
    "\n",
    "First, let's find the sequence of one read. \n",
    "We use `vg view` to convert the small GAM file (with only the reads in the region of interest) to JSON.\n",
    "Below, `head` is used to select the first read, and `jq` is used to format the JSON output nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vg view -a reads.gam | head -1 | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sequence` field in the JSON output contains the sequence of the read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vg view -a reads.gam | head -1 | jq .sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's BLAT this sequence to the GRCh38 reference to see where this read would align best. For that, we can use the [UCSC Genome Browser BLAT Search](https://genome.ucsc.edu/cgi-bin/hgBlat?hgsid=1479064581_Nrp95QbnzkU7WfTiCvsX53igqcAc&command=start)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
