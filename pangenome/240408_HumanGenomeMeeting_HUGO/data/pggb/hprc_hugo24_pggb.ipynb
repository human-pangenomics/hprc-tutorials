{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e2f09-8b5d-4ce0-b081-2b9b61063ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to display image file in this notebook\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e5d09-cc93-4931-b852-0d4f3e50903e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# HPRC HUGO24 Workshop - Building and Analyzing Pangenome Graphs\n",
    "    \n",
    "## PGGB\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- build pangenome graphs using pggb\n",
    "- explore pggb's results\n",
    "- understand how parameters affect the built pangenome graphs\n",
    "\n",
    "### Getting started\n",
    "\n",
    "Make sure you have `pggb` v0.5.4 and its tools installed. It is already available on the course workstations. If you want to build everything on your laptop, follow the instructions at the [pggb homepage](https://github.com/pangenome/pggb) (`guix`, `docker`, `singularity`, and `conda` alternatives are available). So make sure you have checked out pggb repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90fb8a-75b5-4112-8ea5-d0d3726b1668",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pangenome/pggb.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1c1ee-2503-4322-a800-bba6b53ff30c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Build HLA pangenome graphs\n",
    "\n",
    "The [human leukocyte antigen (HLA)](https://en.wikipedia.org/wiki/Human_leukocyte_antigen) system is a complex of genes on chromosome 6 in humans which encode cell-surface proteins responsible for the regulation of the immune system.\n",
    "\n",
    "Let's build a pangenome graph from a collection of sequences of the DRB1-3123 gene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2fda7-4a8b-480d-b04a-22c7136f4684",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pggb -i pggb/data/HLA/DRB1-3123.fa.gz -n 12 -t 8 -o out_DRB1_3123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd80825-de23-4a76-bc17-e943a97e9513",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Run `pggb` without parameters to get information on the meaning of each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d598fe-d408-4d64-80d0-e2910cd4ce29",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pggb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b93e25-02e5-4c45-ab4b-1ca859ff468c",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Take a look at the files in the `out_DRB1_3123` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7425a-c68d-4a95-ba81-ec606ef74fd7",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Image(filename='out_DRB1_3123/DRB1-3123.fa.gz.a130aa2.417fcdf.9c6ea4f.smooth.final.og.viz_multiqc.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45cc6c-27c0-455f-bc27-34f5b800c15d",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Image(filename='out_DRB1_3123/DRB1-3123.fa.gz.a130aa2.417fcdf.9c6ea4f.smooth.final.og.lay.draw_multiqc.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e64ffc-87bb-4d82-b43a-23229e12b149",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Why did we specify `-n 12`?\n",
    "    \n",
    "<details>\n",
    "<summary>Click me for the answer</summary>\n",
    "\n",
    "The pggb graph is defined by the number of mappings per segment of each genome `-n, --n-mappings N`. Ideally, you should set this to equal the number of haplotypes in the pangenome. Because, one expects the `number of haplotypes minus 1` as the maximum number of secondary mappings and alignments. Keep in mind that the total work of alignment is proportional to `N*N`, and these multimappings can be highly redundant. If you provide a `N` that is not equal to the number of haplotypes, provide the actual number of haplotypes to `-H`. This helps smoothxg to determine the right POA problem size.\n",
    "\n",
    "</details>\n",
    "<br/>\n",
    "\n",
    "How many alignments were executed during the pairwise alignment (take a look at the PAF output)? Visualize the alignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7c507-3817-41fc-a570-335a74cbd2b4",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pafplot out_DRB1_3123/*.paf --size 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0107fc-e992-4386-8d79-2a5c009c9d8e",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "See the results at [out_DRB1_3123/DRB1-3123.fa.gz.a130aa2.alignments.wfmash.paf.png](out_DRB1_3123/DRB1-3123.fa.gz.a130aa2.alignments.wfmash.paf.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ee249-ce7a-43bc-8502-03ebf8563ae5",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Image(filename='out_DRB1_3123/DRB1-3123.fa.gz.a130aa2.alignments.wfmash.paf.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820b2577-3f87-456c-9966-4aac45517217",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Use `odgi stats` to obtain the graph length, and the number of nodes, edges, and paths. Do you think the resulting pangenome graph represents the input sequences well? Check the length and the number of the input sequences to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a1568-dedb-45fc-88af-dd366a572589",
   "metadata": {},
   "outputs": [],
   "source": [
    "!odgi stats -Si out_DRB1_3123/DRB1-3123.fa.gz.a130aa2.417fcdf.9c6ea4f.smooth.final.og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183103f9-6612-4afd-b938-d8d46657e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!odgi paths -Lli out_DRB1_3123/DRB1-3123.fa.gz.a130aa2.417fcdf.9c6ea4f.smooth.final.og"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec61748-a79f-45e5-8b91-c67733b93c98",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<details>\n",
    "<summary>Click me for the answer</summary>\n",
    "    \n",
    "The total graph length is much longer than the length of most of the input sequences. This indicates an underalignment of all the sequences.\n",
    "\n",
    "</details>\n",
    "<br/>\n",
    "\n",
    "How many blocks were selected and 'smoothed' during the two rounds of graph normalization?\n",
    "\n",
    "<details> \n",
    "<summary>Hint</summary>\n",
    "    \n",
    "Take a look at the `*.log` file to answer this question.\n",
    "\n",
    "</details>\n",
    "<br />\n",
    "\n",
    "Try building the same pangenome graph by specifying a lower percent identity (`-p 90` by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de754a80-cd3a-4b5d-a605-b9058ac62c78",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pggb -i pggb/data/HLA/DRB1-3123.fa.gz -p 80 -n 12 -t 8 -o out2_DRB1_3123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac71626-6d10-4bd1-b524-756f4d0cc515",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Check graph statistics. Does this pangenome graph represent better or worse the input sequences than the previously produced graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e94b57-a0d8-474d-98f0-1132b58e9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!odgi stats -Si out2_DRB1_3123/DRB1-3123.fa.gz.3b702c0.417fcdf.70ef01d.smooth.final.og"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805071ae-01f4-43a6-8fdf-086deb64f793",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<details>\n",
    "    \n",
    "<summary>Click me for the answer</summary>\n",
    "The total graph length is now closer to each length of most of the input sequences.\n",
    "</details>\n",
    "<br />\n",
    "\n",
    "Try to decrease the number of mappings to keep for each segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9064d-108a-4bdf-9439-f93d7b588ab9",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pggb -i pggb/data/HLA/DRB1-3123.fa.gz -p 80 -n 6 -t 8 -o out3_DRB1_3123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585eb7f-ca35-4908-8d6d-8296ee7b9499",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "How does it affect the graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efde8d-3083-4718-9602-983465aff710",
   "metadata": {},
   "outputs": [],
   "source": [
    "!odgi stats -Si out3_DRB1_3123/DRB1-3123.fa.gz.9a56e7b.417fcdf.351a3ab.smooth.final.og"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04447f36-027e-4705-bcaf-a3f9688d929b",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Try to increase the target sequence length for the partial order alignment (POA) problem (`-G 700,900,1100` by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa8691-2f27-4fe7-b3ae-10dab95ac883",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pggb -i pggb/data/HLA/DRB1-3123.fa.gz -p 80 -n 12 -t 8 -G 1400,1800,2200 -o out4_DRB1_3123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03ac4e-7d75-4cad-a14a-7df4b22f35f3",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "How is this changing the runtime and the memory usage? How is this affecting graph statistics? How many blocks were selected and 'smoothed' during the two rounds of graph normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710cb49-894b-47c1-a6bc-55f53fb7e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!odgi stats -Si out4_DRB1_3123/DRB1-3123.fa.gz.3b702c0.417fcdf.ce2fa85.smooth.final.og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6fb33-e678-4fca-9ed7-5adfd2989f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat out4_DRB1_3123/DRB1-3123.fa.gz.3b702c0.417fcdf.ce2fa85.smooth.04-11-2024_09:12:06.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0bcd2-e2e9-44e5-ac3f-74370b7ad047",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<details>\n",
    "    \n",
    "<summary>Hint</summary>\n",
    "\n",
    "Take a look at the `*.log` file to answer this question.\n",
    "\n",
    "</details>\n",
    "<br />\n",
    "\n",
    "Take the second `pggb` run and try to increase the segment length (`-s 5000` by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae2aae-0bcb-4f5a-9f10-037afe94479f",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pggb -i pggb/data/HLA/DRB1-3123.fa.gz -s 20000 -p 80 -n 12 -t 8 -o out5_DRB1_3123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c7eff-d209-41f6-80be-114689184b43",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "How is this affecting graph statistics? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5c55a-6a5a-49f2-a8da-7aac0fd6f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!odgi stats -Si out5_DRB1_3123/DRB1-3123.fa.gz.0889e72.417fcdf.70ef01d.smooth.final.og"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1c83d-b7d7-48ea-8e6e-5a6e626fd158",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Hint: The length of a segment for mapping is now so large for the given sequence identity, that some mappings are not possible anymore.\n",
    "\n",
    "</details>\n",
    "<br/>\n",
    "\n",
    "\n",
    "## nf-core/pangenome\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "In this exercise you learn how to\n",
    "\n",
    "- run a [nf-core](https://nf-co.re/) [Nextflow](https://www.nextflow.io/) pipeline,\n",
    "- configure the resources according to what is available,\n",
    "- deal with alternative parameter names,\n",
    "- understand the [nf-core/pangenome](https://github.com/nf-core/pangenome) pipeline's output:\n",
    "  - [MutiQC](https://multiqc.info/),\n",
    "  - used CPU, RAM, ...\n",
    "  - workflow timeline,\n",
    "  - output folders\n",
    "\n",
    "### Getting started\n",
    "\n",
    "Make sure you have `wget`, `git`, `Nextflow`, and `Docker` installed. All tools are already available on the course notebook's server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b391ba-6c6b-4965-9b1b-c3aec1ba5e8a",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "One can distribute the available compute resources efficiently across the different processes of the Nextflow pipeline using [config](https://www.nextflow.io/docs/latest/config.html) files. During the course you have access to 8 threads with 16 gigabytes of memory. To ensure that each run only consumes up to these resources, please create a config file `hprc_hugo24.config` with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b92f7a-816a-4d19-8b89-8a33429ef4f1",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "```\n",
    "executor {\n",
    "  cpus = 8\n",
    "  memory = 16.GB\n",
    "}\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7430405-0360-4ebf-aacd-9c66884dccc9",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Prepare input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8033e5-3310-4c64-9947-1f134da8324a",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# download the HPRC PGGB chrY graph\n",
    "#!wget https://s3-us-west-2.amazonaws.com/human-pangenomics/pangenomes/freeze/freeze1/pggb/chroms/chrY.hprc-v1.0-pggb.gfa.gz\n",
    "#!gunzip ../data/chrY.hprc-v1.0-pggb.gfa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1797d8-e3d5-4d4c-9f8e-0938840cd3a5",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We want to build a graph with 4 haplotypes, so we need to extract a subset from all the sequences in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c735b-25a5-4cb4-b2bb-2eed308c6071",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract all sequences in FASTA format with ODGI\n",
    "#!odgi paths -i ../data/chrY.hprc-v1.0-pggb.gfa -f -t 32 -P > chrY.hprc-v1.0-pggb.gfa.fa\n",
    "# index the FASTA\n",
    "#!samtools faidx chrY.hprc-v1.0-pggb.gfa.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec00b7d9-65ad-412a-81e8-e8e1e06fdb60",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We select the two references CHM13, GRCH38, and the 2 haplotypes of the HG01978 diploid sample:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4876c46-0219-45ec-a9cd-8e4cd220fb2f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!grep \"chm13\\|grch38\\|HG01978\" chrY.hprc-v1.0-pggb.gfa.fa.fai | cut -f 1 > chrY.pan4.txt\n",
    "# fetch the sequences of the desired haplotypes\n",
    "#!samtools faidx chrY.hprc-v1.0-pggb.gfa.fa -r chrY.pan4.txt > chrY.hprc.pan4.fa\n",
    "# zip it\n",
    "#!bgzip chrY.hprc.pan4.fa\n",
    "# index the FASTA\n",
    "#!samtools faidx chrY.hprc.pan4.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e58f0-4832-4b75-b4f0-c220b3fb00fe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Building an HPRC 4 haplotypes chrY pangenome graph with nf-core/pangenome\n",
    "\n",
    "Whilst we can limit the maximum allocatable resources with `hprc_hugo24.config`, one can assign resources for each step of the pipeline using a different config file called `chrY.hprc.pan4.config`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b9b9b-4f64-4e9e-9c4d-2de0056313da",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "```\n",
    "process {\n",
    "    withName:'MULTIQC|MULTIQC_COMMUNITY|SAMTOOLS_FAIDX|CUSTOM_DUMPSOFTWAREVERSIONS' {\n",
    "    // these tools can only make use of one thread and need little RAM\n",
    "        cpus = 1\n",
    "        memory = 1.GB\n",
    "    }\n",
    "\n",
    "    withName:'TABIX_BGZIP|ODGI_STATS|WFMASH_ALIGN|VG_DECONSTRUCT' {\n",
    "        cpus = 4\n",
    "        memory = 8.GB\n",
    "    }\n",
    "\n",
    "    withName:'WFMASH_MAP_ALIGN|WFMASH_MAP|SEQWISH|ODGI_BUILD|ODGI_UNCHOP|ODGI_SORT|ODGI_LAYOUT|WFMASH_MAP_COMMUNITY|ODGI_SQUEEZE' {\n",
    "        cpus = 8\n",
    "        memory = 16.GB\n",
    "    }\n",
    "\n",
    "    withName:'SMOOTHXG' {\n",
    "        cpus = 8\n",
    "        memory = 16.GB\n",
    "    }\n",
    "\n",
    "    withName:'GFAFFIX|ODGI_VIEW|ODGI_VIZ*|ODGI_DRAW|SPLIT_APPROX_MAPPINGS_IN_CHUNKS|PAF2NET|NET2COMMUNITIES|EXTRACT_COMMUNITIES' {\n",
    "        // these tools can only make use of one thread and need medium RAM\n",
    "        cpus = 1\n",
    "        memory = 8.GB\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2eb952-3d5f-4581-bcd2-4761716206e4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's build the chromosome 20 pangenome graph. If you are interested in setting additional parameters you can always visit https://nf-co.re/pangenome/1.1.2/parameters for details. All parameters starting with one `-` are handed over to Nextflow, all parameters starting with two `-` are handled by the pipeline itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfb138-b3cf-4a73-ba57-83683210ec1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WARNING: For a better user experience run the line below in a terminal: Click \"+\" -> click \"Terminal\" -> \"cd pggb\".\n",
    "!NXF_SINGULARITY_CACHEDIR=/singularity_cache nextflow run nf-core/pangenome -r 1.1.2 --input ../data/chrY.hprc.pan4.fa.gz --outdir chrY.hprc.pan4_out --n_haplotypes 4 --wfmash_map_pct_id 98 --wfmash_segment_length 10k --wfmash_n_mappings 3 --seqwish_min_match_length 311 --smoothxg_poa_length \"1000,\" -c hprc_hugo24.config,chrY.hprc.pan4.config --wfmash_exclude_delim '#' -profile singularity --wfmash_chunks 4\n",
    "# There might be an ERROR:\n",
    "# FATAL:   container creation failed: mount /proc/self/fd/4->/var/lib/singularity/mnt/session/rootfs error: while mounting image /proc/self/fd/4: failed to find loop device: could not attach image file to loop device: no loop devices available\n",
    "# Please just re-run this cell, it should work then!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416b942-c8a8-487d-87ad-1acf787e2039",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<details>\n",
    "<summary>Click me for the explanations of some Nextflow parameters</summary>\n",
    "    \n",
    " - `nextflow run`: Execute a Nextflow pipeline.\n",
    " - `nf-core/pangenome -r 1.1.2`: Select pipeline https://github.com/nf-core/pangenome for execution in its version 1.1.2.\n",
    " - `--n_haplotypes 4`: We have 4 haplotypes as input.\n",
    " - `--wfmash_map_pct_id 98`: Genomic sequences of human vary by ~2%.\n",
    " - `--wfmash_n_mappings 3`: We want to retain 3 mappings for each segment, because each segment could map to 3 other haplotypes. \n",
    " - `seqwish_min_match_length 311`: Filter exact matches below this length. This can smooth the graph locally and prevent the formation of complex local graph topologies from forming due to differential alignments.\n",
    " - `--wfmash_exclude_delim '#'`: Our input sequences follows the pansn spec so the idea is to skip mappings when the query and target have the same\n",
    "prefix: '#'. Since our sample `HG01978` still consists of contigs, this will reduce our mapping problem and speed up `WFMASH_MAP`.\n",
    " - `--wfmash_chunks 4`: One advantage that `nf-core/pangenome` has over `pggb` is that it can parallelize the often heavy base-pair level alignments across nodes of a cluster. The parameter `--wfmash_chunks` determines into how many equally large subproblems the alignments should be split after the `WFMASH_MAP` process. It is recommended that this number roughly fits the number of available nodes one has. During the course, a full cluster is not available, so we are improvising. In `chrY.hprc.pan4.config` the number of CPUs for `WFMASH_ALIGN` is set to 8. Assuming we are able to run this in parallel on our 8T/16GB machine, one can expect that at most 2 `WFMASH_ALIGN` process can be executed in parallel.\n",
    "</details>\n",
    "<br />\n",
    "\n",
    "*In which folder can the final ODGI graph be found? And in which folder in the final GFA graph?*\n",
    "\n",
    "<details>\n",
    "<summary>Click me for the answer</summary>\n",
    "    \n",
    " - ODGI: *FINAL_ODGI*\n",
    " - GFA: *FINAL_GFA*\n",
    "</details>\n",
    "    \n",
    "Open the MultiQC report and other statistics on your local machine in order to take a closer look.\n",
    "\n",
    "    chrY.hprc.pan4_out/multiqc/multiqc_report.html .\n",
    "    chrY.hprc.pan4_out/pipeline_info/execution_*.html .\n",
    "    chrY.hprc.pan4_out/pipeline_info/pipeline_dag_*.html .\n",
    "\n",
    "In the MultiQC report you will find vital graph statistics, lots of 1D graph visualizations and a 2D graph visualization serving both as quantitative and qualitative graph validation information. In `execution_report_*.html*` you can find an overview of the executed pipeline and especially the resource consumption of each process of the pipeline. If you notice that a process is consuming much less RAM than it was given in `chrY.hprc.pan4.config` you would want to adjust this in future runs. Assuming you want to run `nf-core/pangenome` on a cluster, it is crucial to limit the allocated resources for each process, so your jobs usually have a higher chance to be submitted by the cluster scheduler. In `execution_timeline_*.html` one can observe when which process was executed and which processes were submitted in parallel, assuming resources were available.\n",
    "\n",
    "## ODGI\n",
    "### Learning objectives\n",
    "\n",
    "- extract subgraphs representing loci of interest\n",
    "- visualize graph annotation\n",
    "- make phylogenetic trees\n",
    "\n",
    "### Getting started\n",
    "\n",
    "Check out odgi repository (we need one of its example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97124f7-b6fa-4409-8fb6-98df7e4a76dd",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pangenome/odgi.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53842cc1-2b96-4161-aca9-f9a5006faf12",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Exploring the HPRC chromosome 6 pangenome graph\n",
    "\n",
    "Download the pangenome graph of the Human chromosome 6 in GFA format, decompress it, and convert it to a graph in odgi format.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e5b43-f02e-475f-a10f-f2ead7729868",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://s3-us-west-2.amazonaws.com/human-pangenomics/pangenomes/scratch/2021_11_16_pggb_wgg.88/chroms/chr6.pan.fa.a2fb268.4030258.6a1ecc2.smooth.gfa.gz\n",
    "# !gunzip ../data/chr6.pan.fa.a2fb268.4030258.6a1ecc2.smooth.gfa.gz\n",
    "# !odgi build -g ../data/chr6.pan.fa.a2fb268.4030258.6a1ecc2.smooth.gfa -o chr6.pan.og -t 8 -P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd94366-b321-4b4f-96ac-f1f069be9616",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This graph contains contigs of 88 haploid, phased human genome assemblies from 44 individuals, plus the `chm13` and `grch38` reference genomes.\n",
    "\n",
    "#### Extraction\n",
    "\n",
    "The [major histocompatibility complex (MHC)](https://en.wikipedia.org/wiki/Major_histocompatibility_complex) is a large locus in vertebrate DNA containing a set of closely linked polymorphic genes that code for cell surface proteins essential for the adaptive immune system. In humans, the MHC region occurs on chromosome 6. The human MHC is also called the HLA (human leukocyte antigen) complex (often just the HLA).\n",
    "\n",
    "To see the coordinates of some HLA genes, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8269e-3b5b-4d96-9a3f-78576b655b8f",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!head odgi/test/chr6.HLA_genes.bed -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235ca21-b7d3-4812-b965-df660c9e2c01",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The coordinates are expressed with respect to the `grch38` reference genome.\n",
    "\n",
    "To extract the subgraph containing all the HLA genes annotated in the `chr6.HLA_genes.bed` file, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e96a9-c42c-4d7d-85fb-21cbfd49dac7",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!odgi extract -i ../data/chr6.pan.og -o chr6.pan.MHC.og -b <(bedtools merge -i odgi/test/chr6.HLA_genes.bed -d 10000000) -d 0 -E -t 8 -P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078fe85-f118-4233-a8c9-b56ff708a51f",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !odgi extract -i chr6.pan.og -o chr6.pan.MHC.og -b odgi/test/chr6.HLA_genes.bed -d 0 -E -t 8 -P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8cf5b-e16c-4322-824f-64aab7c9bc8f",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The instruction extracts:\n",
    "\n",
    "- the nodes belonging to the `grch38#chr6` path ranges specified in the the `chr6.HLA_genes.bed` file via `-b`,\n",
    "- all nodes between the min and max positions touched by the given path ranges, also if they belong to other paths (`-E`),\n",
    "- the edges connecting all the extracted nodes, and\n",
    "- the paths traversing all the extracted nodes.\n",
    "\n",
    "How many paths are present in the extracted subgraph? With 90 haplotypes (44 diploid samples plus 2 haploid reference genomes), how many paths would you expect in the subgraph if the MHC locus were solved with a single contig per haplotype?\n",
    "\n",
    "To visualize the graph, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99a365-6fe1-4d6a-baca-7f2e94d7dc46",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!odgi sort -i chr6.pan.MHC.og -o - -O | odgi viz -i - -o chr6.pan.MHC.png -s '#' -a 20\n",
    "Image(filename='chr6.pan.MHC.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80517428-90cc-4570-892f-cbfcc4225da8",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Why are we using `odgi sort` before visualizing the graph?\n",
    "\n",
    "Are there haplotypes where the MHC locus is not resolved with a single contig? If so, which ones? Count the number of contigs for each haplotype.\n",
    "\n",
    "Generate the graph layout with `odgi layout`. (remember to specify the number of threads). Visualize the layout with `odgi draw` Specify `-P` to get information on the progress.\n",
    "\n",
    "The MHC locus includes the complement component 4 (C4) region, which encodes proteins involved in the complement system. In humans, the C4 gene exists as 2 functionally distinct genes, C4A and C4B, which both vary in structure and copy number ([Sekar et al., 2016](https://www.nature.com/articles/nature16549)). Moreover, C4A and C4B genes segregate in both long and short genomic forms, distinguished by the presence or absence of a human endogenous retroviral (HERV) sequence.\n",
    "\n",
    "Find C4 coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52575b6c-ec4a-49dd-a778-a9e91ab5c65c",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes\n",
    "#!wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/genes/hg38.ncbiRefSeq.gtf.gz\n",
    "#!zgrep 'gene_id \"C4A\"\\|gene_id \"C4B\"' ../data/hg38.ncbiRefSeq.gtf.gz | awk '$1 == \"chr6\"' | cut -f 1,4,5 | bedtools sort | bedtools merge -d 15000 | bedtools slop -l 10000 -r 20000 -g ../data/hg38.chrom.sizes | sed 's/chr6/grch38#chr6/g' > hg38.ncbiRefSeq.C4.coordinates.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e721005-e550-4610-9edf-cd27a895ea28",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Extract the C4 locus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741f85d-8cca-41b7-8322-b16c731b2eb6",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!odgi extract -i ../data/chr6.pan.og -b ../data/hg38.ncbiRefSeq.C4.coordinates.bed -o - -d 0 -E -t 8 -P | odgi explode -i - --biggest 1 --sorting-criteria P --optimize -p chr6.pan.C4\n",
    "!odgi sort -i chr6.pan.C4.0.og -o chr6.pan.C4.sorted.og -p Ygs -x 100 -t 8 -P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527d1e8-e2f1-4c62-994d-3a061f1c6d69",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "What is `odgi explode` is doing?\n",
    "\n",
    "Regarding the `odgi viz` visualization, select the haplotypes to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cfd5a2-0c11-4957-89d6-d2e0b9209e90",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!odgi paths -i chr6.pan.C4.sorted.og  -L | grep 'chr6\\|HG00438\\|HG0107\\|HG01952' > chr6.selected_paths.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8984341-245d-4158-99f1-66e7ab0bbb0d",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5df1c8-21ac-43fb-b016-a3941a9bab64",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# odgi viz: default (binned) mode\n",
    "!odgi viz -i chr6.pan.C4.sorted.og -o chr6.pan.C4.sorted.png -c 12 -w 100 -y 50 -p chr6.selected_paths.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95047f-9e68-4854-ab5c-13da7c5e6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='chr6.pan.C4.sorted.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856f2ea-7b6a-4793-bdd4-bc02ceeb683b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# odgi viz: color by strand\n",
    "!odgi viz -i chr6.pan.C4.sorted.og -o chr6.pan.C4.sorted.z.png -c 12 -w 100 -y 50 -p chr6.selected_paths.txt -z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3cf08d-063c-482e-8554-3f3d5f689768",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='chr6.pan.C4.sorted.z.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd751b46-ef75-4779-b129-bf5ab7d69a43",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# odgi viz: color by position\n",
    "!odgi viz -i chr6.pan.C4.sorted.og -o chr6.pan.C4.sorted.du.png -c 12 -w 100 -y 50 -p chr6.selected_paths.txt -du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734ca91-0dec-4b3f-8466-30a0b6a2d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='chr6.pan.C4.sorted.du.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c780d3-3ea7-406a-ab30-1e3a309fa82c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# odgi viz: color by depth\n",
    "!odgi viz -i chr6.pan.C4.sorted.og -o chr6.pan.C4.sorted.m.png -c 12 -w 100 -y 50 -p chr6.selected_paths.txt -m -B Spectral:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac6664-5bdb-4355-953b-de5ade909c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='chr6.pan.C4.sorted.m.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e65c0c2-480b-4032-9465-5101b60b949a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "For the `chr6.pan.C4.sorted.m.png` image we used the Spectra color palette with 4 levels of node depths, so white indicates no depth, while grey, red, and yellow indicate depth 1, 2, and greater than or equal to 3, respectively. What information does this image provide us about the state of the C4 region in the selected haplotypes?\n",
    "\n",
    "Visualize all haplotypes with `odgi viz`, coloring by depth. How many haplotypes have three copies of the C4 region? How many haplotypes are missing the HERV sequence? What is the copy number state of the `chm13` and `grch38` reference genomes?\n",
    "\n",
    "Use `odgi layout` and `odgi draw` to compute and visualize the layout of the C4 locus. Try to find out how to add the following /home/participant/odgi/test/chr6.C4.bed to `odgi draw`'s SVG output. The HERV sequence may be present or absent in the C4 regions across haplotypes: how does this reflect on the structure of the graph?\n",
    "\n",
    "### Primate chromosome 6\n",
    "\n",
    "Download the pangenome graph of the primate chromosome 6 in GFA format, decompress it, and convert it to a graph in `odgi` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cd6de-6c54-4885-bae4-4656eed62684",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!wget https://zenodo.org/record/7933393/files/primates14.chr6.fa.gz.667b9b6.c2fac19.ee137be.smooth.final.gfa.zst\n",
    "#!zstd -d ../data/primates14.chr6.fa.gz.667b9b6.c2fac19.ee137be.smooth.final.gfa.zst\n",
    "#!odgi build -g ../data/primates14.chr6.fa.gz.667b9b6.c2fac19.ee137be.smooth.final.gfa -o primates14.chr6.fa.gz.667b9b6.c2fac19.ee137be.smooth.final.og -t 8 -P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc3959-9c10-4045-95ad-aec1603ee6d4",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This graph contains contigs of chromosome 6 of six diploid (2 haplotypes for each sample), phased primate genome assemblies, plus the chm13 and grch38 reference genomes. Primate genomes were downloaded from https://genomeark.github.io/t2t-all/.\n",
    "\n",
    "Compute the dissimilarity (distance) between all possible pairs of haplotypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ba20f-0f39-46b6-bbdb-74591e9eb65b",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!odgi similarity -i ../data/primates14.chr6.fa.gz.667b9b6.c2fac19.ee137be.smooth.final.og --distances -t 8 -D '#' -p 2 -P > primates14.chr6.fa.gz.667b9b6.c2fac19.ee137be.smooth.final.dist.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107703c-d6d5-4408-882d-b5e8e4bca9a5",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The `-D` and `-p` options specifies to use the 2nd occurrence of the # character to group the results. As path names follow the PanSN-spec specification, this means that results are grouped by haplotype. Take a look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f029855-cb58-421a-acc9-6be8c8680c49",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!head primates14.chr6.fa.gz.667b9b6.c2fac19.ee137be.smooth.final.dist.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe0d96-8556-457b-825c-1854fe387c6b",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Construct a phylogenetic tree by using the jaccard.distance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f6d4b-740a-4bf8-8543-5296db2463e8",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "    library(tidyverse)\n",
    "    library(ape)\n",
    "    library(ggtree)\n",
    "\n",
    "    path_dist_tsv <- 'primates14.chr6.fa.gz.667b9b6.c2fac19.ee137be.smooth.final.dist.tsv'\n",
    "\n",
    "    # Read sparse matrix\n",
    "    sparse_matrix_df <- read_tsv(path_dist_tsv)\n",
    "\n",
    "    # Prepare distance matrix\n",
    "    jaccard_dist_df <- sparse_matrix_df %>%\n",
    "      arrange(group.a, group.b) %>%\n",
    "      select(group.a, group.b, dice.distance) %>%\n",
    "      pivot_wider(names_from = group.b, values_from = dice.distance) %>%\n",
    "      column_to_rownames(var = \"group.a\")\n",
    "\n",
    "    # Clustering\n",
    "    jaccard_hc <- as.dist(jaccard_dist_df) %>% hclust()\n",
    "\n",
    "    # Open a pdf device with the specified width and height\n",
    "    pdf(file = \"dendrogram.haplotypes.pdf\", width = 5, height = 6)\n",
    "\n",
    "    # Plot the dendrogram\n",
    "    plot(\n",
    "      jaccard_hc,\n",
    "\n",
    "      # Label at same height\n",
    "      hang = -1,\n",
    "      main = 'primate14.chr6',\n",
    "      xlab = 'Haplotype',\n",
    "      ylab = 'Jaccard distance',\n",
    "      sub = '',\n",
    "      cex = 1.2\n",
    "    )\n",
    "\n",
    "    # Close the device and save the file\n",
    "    dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba14e9-7424-47ae-8836-d4932427725c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!Rscript make_dendrogram_primates.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8a40f-4577-476a-84cd-c856b3b2f944",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Image(filename='dendrogram.haplotypes.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d21e1e-1737-4177-bcd8-8a12c7a1fd60",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Try to make the tree by grouping the results by sample.\n",
    "\n",
    "## Bonus: Pangenome growth curve\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "In this exercise you learn how to\n",
    "\n",
    "- Evaluate and interpret the growth curve of a pangenome.\n",
    "\n",
    "### Getting started\n",
    "\n",
    "Make sure you have `panacus` installed. It is already available on the course VMs.\n",
    "\n",
    "Now create a directory to work on for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e6de7-aedf-4b4a-95de-2070d2fe802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd ~\n",
    "#!mkdir -p hprc_openness\n",
    "#!cd hprc_openness\n",
    "#!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb9988-b191-4ce2-a403-eb1c5fdd2ca9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Download the 44 haplotypes chrM HPRC human pangenome graph ([Liao, Asri, Ebler et al., 2023](https://doi.org/10.1038/s41586-023-05896-x)) from the [HPRC Pangenome Resources](https://github.com/human-pangenomics/hpp_pangenome_resources) and the 50 haplotypes *E. coli* pangenome graph ([Garrison, Guarracino et al., 2023](https://www.biorxiv.org/content/10.1101/2023.04.05.535718v1)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4e768-b74c-4b20-93f2-3fe498b55b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p chrM\n",
    "#!cd chrM\n",
    "#!wget -c https://s3-us-west-2.amazonaws.com/human-pangenomics/pangenomes/freeze/freeze1/pggb/chroms/chrM.hprc-v1.0-pggb.gfa.gz\n",
    "#!gunzip chrM.hprc-v1.0-pggb.gfa.gz\n",
    "#!mv chrM.hprc-v1.0-pggb.gfa chrM.gfa\n",
    "#!cd ..\n",
    "\n",
    "#!mkdir -p ecoli50\n",
    "#!cd ecoli50\n",
    "#!wget -c https://zenodo.org/record/7937947/files/ecoli50.gfa.zst\n",
    "#!zstd -d ecoli50.gfa.zst\n",
    "#!cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14236b6f-5eb7-45c6-896a-3555de1a0c8d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### `odgi heaps`\n",
    "\n",
    "`odgi heaps` calculates permutations of the path pangenome coverage in the graph. The number of  permutations affects the accuracy of the subsequent power law regression. This regression happens in this [Rscript](https://github.com/pangenome/odgi/blob/master/scripts/heaps_fit.R) that uses the heap's law ([Tettelin et al., 2008](https://www.sciencedirect.com/science/article/pii/S1369527408001239?via=ihub#section0020)) to calculate a pangenome growth curve from all `odgi heaps` permutations. For more details, take a look at https://en.wikipedia.org/wiki/Pan-genome#Classification.\n",
    "\n",
    "### `Panacus`\n",
    "\n",
    "`panacus` is able to calculate the pangenome openness without the need to perform any permutations. Indeed, it directly applies the binomial formula described in [Parmigiani et al., 2022](https://www.biorxiv.org/content/10.1101/2022.11.15.516472v2), Section 2.1, Eq 1.\n",
    "\n",
    "`panacus` exposes a parameter (`-c`) that allow users to chose which graph feature (sequence, node, edge) is taken into account to calculate the growth histogram  parameter. The coverage `-l` parameter sets the _minimum number_ of haplotypes visiting a graph feature in order for this graph feature to be included into the calculation at all. With `-q` one can set the _minimum fraction_ of haplotypes that must share a graph feature *after each time a haplotype is added to the growth histograph*.\n",
    "\n",
    "For example, assuming a 100 haplotypes pangenome graph, setting `-c bps -q 0,1,0.5,0.1` would calculate the pangenome growth in sequence scape (`-c bps`) for 4 different cases. Remember, quorum sets the minimum fraction of haplotypes for a nucleotide to be included in the openness calculation.\n",
    "\n",
    "- without setting any quorum (`-q 0`), so all sequences are considered.\n",
    "- limited to sequences that are traversed by 100% of haplotypes (`-q 1`). This is the `core pangenome`.\n",
    "- limited to sequences that are traversed by at least 50% of the haplotypes (`-q 0.5`). This is the `shell pangenome`.\n",
    "- limited to sequences that are traversed by at least 10% of the haplotypes (`-q 0.1`). This is the `cloud pangenome`.\n",
    "\n",
    "`panacus` fits two curves, one following heap's law, and one using heap's power law for modeling the data.\n",
    "\n",
    "### Pangenome growth curve of the HPRC chrM pangenome graph\n",
    "\n",
    "Create the matrix of path pangenome coverage permutations of the chrM graph with `odgi heaps` subsequently performing the heap's law regression:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c696d5e-dfa6-4173-b37b-8bd4e04a27e5",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!cd chrM\n",
    "!odgi heaps -i ../data/chrM.gfa -S -n 100 > chrM.gfa.heaps.tsv\n",
    "!Rscript odgi/scripts/heaps_fit.R chrM.gfa.heaps.tsv chrM.gfa.heaps.tsv.pdf # this should be executed on your local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958d2dc-3c92-4770-ab38-86b3aef6f91f",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Taking a look at the PDF, we can surprisingly observe 2 traces of permutations. *How can this happen*? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7baaa7-6d7f-449b-87ac-29736f87cea5",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "    \n",
    "<summary>**Hint**</summary>\n",
    "    \n",
    "Take a look at the 1D visualization of the graph.\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>**Explanation**</summary>\n",
    "    \n",
    "The CHM13 reference was linearized differently than all the other mitochondrial sequences. Therefore it has an additional `tip`. `odgi heaps` permutation algorithm is reflecting this, because the permutation always starts with the beginning of each genome.\n",
    "\n",
    "</details>\n",
    "\n",
    "So to get a cleaner pangenome growth curve with `odgi heap` we remove the CHM13 reference sequence and run the analysis again:\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c34bf-3834-4cd6-8d09-f91157765cde",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!odgi paths -i ../data/chrM.gfa -L | head -n 1 > chrM.gfa.chm13\n",
    "!odgi paths -i ../data/chrM.gfa -X chrM.gfa.chm13 -o chrM.gfa.no_chm13.og\n",
    "!odgi heaps -i chrM.gfa.no_chm13.og -S -n 100 > chrM.gfa.no_chm13.og.heaps.tsv\n",
    "!Rscript odgi/scripts/heaps_fit.R chrM.gfa.no_chm13.og.heaps.tsv chrM.gfa.heaps.no_chm13.og.tsv.pdf # this should be executed on your local machine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd21b3-bbce-4cf4-aef8-1e0501a11f43",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This looks much better! With every added genome, the number of newly added bases is really low. Let's take a closer look with `panacus`.\n",
    "    \n",
    "Create and visualize a growth histogramm of the chrM graph in sequence space with `panacus`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a119b4-55af-43a9-a41e-13b676330aaf",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!RUST_LOG=info panacus histgrowth ../data/chrM.gfa -c bp -q 0,1,0.5,0.1 -t 8 > chrM.gfa.histgrowth.tsv\n",
    "!panacus-visualize -e -l \"lower right\" chrM.gfa.histgrowth.tsv > chrM.gfa.histgrowth.tsv.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df04da-2c62-4d2d-999b-85dbe217826f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[chrM.gfa.histgrowth.tsv.pdf](chrM.gfa.histgrowth.tsv.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc0674-effa-4d4f-b0d8-021c3b73ff99",
   "metadata": {},
   "source": [
    "### Pangenome growth curve of the HPRC chrM pangenome graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09340e-9816-48d1-b306-f8df92e7603f",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!odgi heaps -i ../data/ecoli50.gfa -S -n 100 -t 8 -P > ecoli50.gfa.heaps.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908abd40-aad9-474b-a6cb-95e98f46f792",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!Rscript odgi/scripts/heaps_fit.R ecoli50.gfa.heaps.tsv ecoli50.gfa.heaps.tsv.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783550a4-4ba1-4ffa-8adb-9cb0e7ffd5a1",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[ecoli50.gfa.heaps.tsv.pdf](ecoli50.gfa.heaps.tsv.pdf)\n",
    "\n",
    "With every added genome, the number of newly added bases is at least 100k.  Let's take a closer look with `panacus`.\n",
    "\n",
    "Create and visualize a growth histograph of the *E. coli* graph in sequence space with `panacus`:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3b0df-4b50-44e9-bb8b-93c8663eca59",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!RUST_LOG=info panacus histgrowth ../data/ecoli50.gfa -c bp -q 0,1,0.5,0.1 -t 8 > ecoli50.gfa.histgrowth.tsv\n",
    "!panacus-visualize -e -l \"upper left\" ecoli50.gfa.histgrowth.tsv > ecoli50.gfa.histgrowth.tsv.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b9cdb9-b818-4288-8e14-56d6a9bfdd22",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "[ecoli50.gfa.histgrowth.tsv.pdf](ecoli50.gfa.histgrowth.tsv.pdf)\n",
    "\n",
    "Taking a look at the top Figure in the PDF there is a polynomial growth of the number of nucleotides with increasing number of genomes visible. \n",
    "\n",
    "The bottom Figure shows the added number of bases per added individual. Even the 50th added individual adds more than 100k new bases to the pangenome. In conclusion, the *E. coli* pangenome is open. The core pangenome (`quorum >= 1`) is quite small, with the shell pangenome (`quorum >= 0.5`) not adding much more sequence, and the cloud pangenome (`quorum >= 0.1`) adding some more sequence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "name": "hprc_hugo24_pggb.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
